package chunker

import (
	"fmt"
	"log"
	"strings"

	"github.com/yuin/goldmark"
	"github.com/yuin/goldmark/ast"
	"github.com/yuin/goldmark/text"
)

// MarkdownChunker —Ä–∞–∑–±–∏–≤–∞–µ—Ç markdown –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –≤—ã–±–æ—Ä–æ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
type MarkdownChunker struct {
	config Config
}

// NewMarkdownChunker —Å–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–π markdown chunker
func NewMarkdownChunker(config Config) *MarkdownChunker {
	return &MarkdownChunker{config: config}
}

func (m *MarkdownChunker) Name() string {
	return "markdown"
}

// DocumentStructure —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
type DocumentStructure struct {
	HeadingCounts   map[int]int // —É—Ä–æ–≤–µ–Ω—å –∑–∞–≥–æ–ª–æ–≤–∫–∞ -> –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
	TotalParagraphs int
	TotalSize       int
}

// ChunkingStrategy –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Ä–∞–∑–±–∏–µ–Ω–∏—è
type ChunkingStrategy struct {
	Level int // —É—Ä–æ–≤–µ–Ω—å –∑–∞–≥–æ–ª–æ–≤–∫–∞ (2-4)
}

func (m *MarkdownChunker) Chunk(content, source string) ([]Chunk, error) {
	md := goldmark.New()
	reader := text.NewReader([]byte(content))
	doc := md.Parser().Parse(reader)

	// –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞
	structure := m.analyzeStructure(doc)

	// –í—ã–±–∏—Ä–∞–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Ä–∞–∑–±–∏–µ–Ω–∏—è
	strategy, err := m.selectStrategy(structure)
	if err != nil {
		// –Ø–≤–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É - –ø—É—Å—Ç—å –≤—ã–∑—ã–≤–∞—é—â–∏–π –∫–æ–¥ —Ä–µ—à–∞–µ—Ç —á—Ç–æ –¥–µ–ª–∞—Ç—å
		return nil, fmt.Errorf("markdown chunker cannot process this content: %w", err)
	}

	log.Printf("üìä [%s] Document structure: headings=%v, paragraphs=%d",
		m.Name(), structure.HeadingCounts, structure.TotalParagraphs)
	log.Printf("üéØ [%s] Selected strategy: heading (level %d)", m.Name(), strategy.Level)

	// –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Ä–∞–∑–±–∏–µ–Ω–∏—è –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º
	chunks := m.chunkByHeadings(doc, []byte(content), source, strategy.Level)

	log.Printf("‚úÖ [%s] Created %d chunks", m.Name(), len(chunks))
	return chunks, nil
}

// analyzeStructure –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É markdown –¥–æ–∫—É–º–µ–Ω—Ç–∞
func (m *MarkdownChunker) analyzeStructure(doc ast.Node) DocumentStructure {
	structure := DocumentStructure{
		HeadingCounts: make(map[int]int),
	}

	ast.Walk(doc, func(n ast.Node, entering bool) (ast.WalkStatus, error) {
		if entering {
			if heading, ok := n.(*ast.Heading); ok {
				structure.HeadingCounts[heading.Level]++
			}
			if _, ok := n.(*ast.Paragraph); ok {
				structure.TotalParagraphs++
			}
		}
		return ast.WalkContinue, nil
	})

	return structure
}

// selectStrategy –≤—ã–±–∏—Ä–∞–µ—Ç —É—Ä–æ–≤–µ–Ω—å –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è
func (m *MarkdownChunker) selectStrategy(structure DocumentStructure) (ChunkingStrategy, error) {
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –æ—Ç H2 –¥–æ H4 (–Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–µ –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)
	for level := 2; level <= 4; level++ {
		count := structure.HeadingCounts[level]
		// –ï—Å–ª–∏ –µ—Å—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —ç—Ç–æ–≥–æ —É—Ä–æ–≤–Ω—è - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
		minHeadings := 3
		switch level {
		case 2:
			minHeadings = 3 // –î–ª—è H2 (—Å—Ç–∞—Ç—å–∏) –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ 3
		case 3:
			minHeadings = 5 // –î–ª—è H3 (–ø–æ–¥—Ä–∞–∑–¥–µ–ª—ã) –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ
		default:
			minHeadings = 10 // –î–ª—è H4 –Ω—É–∂–Ω–æ –µ—â—ë –±–æ–ª—å—à–µ
		}

		if count >= minHeadings {
			return ChunkingStrategy{Level: level}, nil
		}
	}

	// –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–µ–π markdown —Å—Ç—Ä—É–∫—Ç—É—Ä—ã - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
	return ChunkingStrategy{}, fmt.Errorf(
		"no suitable markdown structure found (headings: %v, paragraphs: %d)",
		structure.HeadingCounts, structure.TotalParagraphs,
	)
}

// chunkByHeadings —Ä–∞–∑–±–∏–≤–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è
func (m *MarkdownChunker) chunkByHeadings(doc ast.Node, content []byte, source string, targetLevel int) []Chunk {
	var chunks []Chunk
	var currentChunk strings.Builder
	var currentSection string
	var parentSection string // –î–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–æ–≤
	var currentLevel int

	ast.Walk(doc, func(n ast.Node, entering bool) (ast.WalkStatus, error) {
		if entering {
			if heading, ok := n.(*ast.Heading); ok {
				headingText := extractText(heading, content)

				// –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ü–µ–ª–µ–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è –∏–ª–∏ –≤—ã—à–µ - –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π —á–∞–Ω–∫
				if heading.Level <= targetLevel {
					if currentChunk.Len() > 0 {
						// –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —á–∞–Ω–∫
						chunks = append(chunks, m.finalizeChunk(
							currentChunk.String(),
							source,
							currentSection,
							parentSection,
							currentLevel,
						)...)
						currentChunk.Reset()
					}

					currentSection = headingText
					currentLevel = heading.Level

					// –û–±–Ω–æ–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é —Å–µ–∫—Ü–∏—é
					if heading.Level == targetLevel {
						parentSection = headingText
					}

					currentChunk.WriteString(headingText + "\n\n")
				} else {
					// –ü–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤–∫–ª—é—á–∞–µ–º –≤ —Ç–µ–∫—É—â–∏–π —á–∞–Ω–∫
					currentChunk.WriteString("\n" + headingText + "\n\n")
				}
			} else if textNode, ok := n.(*ast.Text); ok {
				currentChunk.Write(textNode.Segment.Value(content))
			}
		} else {
			if _, ok := n.(*ast.Paragraph); ok {
				currentChunk.WriteString("\n\n")
			}
		}
		return ast.WalkContinue, nil
	})

	// –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫
	if currentChunk.Len() > 0 {
		chunks = append(chunks, m.finalizeChunk(
			currentChunk.String(),
			source,
			currentSection,
			parentSection,
			currentLevel,
		)...)
	}

	return chunks
}

// finalizeChunk –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —á–∞–Ω–∫: —Ä–∞–∑–±–∏–≤–∞–µ—Ç –µ—Å–ª–∏ –±–æ–ª—å—à–æ–π, –¥–æ–±–∞–≤–ª—è–µ—Ç overlap –¥–ª—è –ø–æ–¥—Ä–∞–∑–¥–µ–ª–æ–≤
func (m *MarkdownChunker) finalizeChunk(text, source, section, parentSection string, level int) []Chunk {
	text = strings.TrimSpace(text)

	// –ï—Å–ª–∏ —á–∞–Ω–∫ –º–µ–Ω—å—à–µ –ª–∏–º–∏—Ç–∞ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
	if len(text) <= m.config.MaxChunkSize {
		metadata := map[string]string{
			"level": fmt.Sprintf("%d", level),
		}
		if parentSection != "" && parentSection != section {
			metadata["parent_section"] = parentSection
		}
		return []Chunk{CreateChunk(text, source, section, metadata)}
	}

	// –†–∞–∑–±–∏–≤–∞–µ–º –±–æ–ª—å—à–æ–π —á–∞–Ω–∫ –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º
	return m.splitLargeChunk(text, source, section, parentSection, level)
}

// splitLargeChunk —Ä–∞–∑–±–∏–≤–∞–µ—Ç –±–æ–ª—å—à–æ–π —á–∞–Ω–∫ –Ω–∞ —á–∞—Å—Ç–∏ —Å —É–º–Ω—ã–º overlap
func (m *MarkdownChunker) splitLargeChunk(text, source, section, parentSection string, level int) []Chunk {
	paragraphs := SplitByParagraphs(text)
	var chunks []Chunk
	var currentPart strings.Builder
	partNum := 1
	var prevTail string

	// –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–µ–Ω –ª–∏ overlap (—Ç–æ–ª—å–∫–æ –¥–ª—è –ø–æ–¥—Ä–∞–∑–¥–µ–ª–æ–≤)
	useOverlap := level > 2 && m.config.Overlap > 0

	for _, para := range paragraphs {
		// –ï—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –ø—Ä–µ–≤—ã—Å–∏—Ç –ª–∏–º–∏—Ç
		if currentPart.Len() > 0 && currentPart.Len()+len(para) > m.config.MaxChunkSize {
			partText := currentPart.String()

			// –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â—É—é —á–∞—Å—Ç—å
			sectionWithPart := section
			if partNum > 1 {
				sectionWithPart = fmt.Sprintf("%s (—á–∞—Å—Ç—å %d)", section, partNum)
			}

			metadata := map[string]string{
				"level":     fmt.Sprintf("%d", level),
				"part":      fmt.Sprintf("%d", partNum),
				"has_parts": "true",
			}
			if parentSection != "" && parentSection != section {
				metadata["parent_section"] = parentSection
			}

			chunks = append(chunks, CreateChunk(partText, source, sectionWithPart, metadata))

			// –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ö–≤–æ—Å—Ç –¥–ª—è overlap
			if useOverlap {
				prevTail = GetLastNChars(partText, m.config.Overlap)
			}

			currentPart.Reset()

			// –î–æ–±–∞–≤–ª—è–µ–º overlap –≤ –Ω–∞—á–∞–ª–æ –Ω–æ–≤–æ–π —á–∞—Å—Ç–∏
			if useOverlap && prevTail != "" {
				currentPart.WriteString(prevTail)
				currentPart.WriteString("\n\n")
			}

			partNum++
		}

		if currentPart.Len() > 0 {
			currentPart.WriteString("\n\n")
		}
		currentPart.WriteString(para)
	}

	// –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —á–∞—Å—Ç—å
	if currentPart.Len() > 0 {
		sectionWithPart := section
		if partNum > 1 {
			sectionWithPart = fmt.Sprintf("%s (—á–∞—Å—Ç—å %d)", section, partNum)
		}

		metadata := map[string]string{
			"level": fmt.Sprintf("%d", level),
		}
		if partNum > 1 {
			metadata["part"] = fmt.Sprintf("%d", partNum)
			metadata["has_parts"] = "true"
		}
		if parentSection != "" && parentSection != section {
			metadata["parent_section"] = parentSection
		}

		chunks = append(chunks, CreateChunk(currentPart.String(), source, sectionWithPart, metadata))
	}

	return chunks
}

// extractText –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —É–∑–ª–∞ AST
func extractText(node ast.Node, source []byte) string {
	var buf strings.Builder
	for child := node.FirstChild(); child != nil; child = child.NextSibling() {
		if textNode, ok := child.(*ast.Text); ok {
			buf.Write(textNode.Segment.Value(source))
		}
	}
	return buf.String()
}
